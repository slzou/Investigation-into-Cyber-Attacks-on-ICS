{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading useful packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import networkx as nx\n",
    "import collections\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data sets and combining them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = glob.glob('F:\\\\SWaT Dataset\\\\*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading file: F:\\SWaT Dataset\\2015-12-29_190411_104.log.part01_sorted.csv\n",
      "loading file: F:\\SWaT Dataset\\2015-12-29_190411_104.log.part02_sorted.csv\n",
      "loading file: F:\\SWaT Dataset\\2015-12-29_190411_104.log.part03_sorted.csv\n",
      "loading file: F:\\SWaT Dataset\\2015-12-29_190411_104.log.part04_sorted.csv\n",
      "loading file: F:\\SWaT Dataset\\2015-12-29_190411_104.log.part05_sorted.csv\n",
      "loading file: F:\\SWaT Dataset\\2015-12-29_190411_104.log.part06_sorted.csv\n",
      "loading file: F:\\SWaT Dataset\\2015-12-29_190411_104.log.part07_sorted.csv\n",
      "loading file: F:\\SWaT Dataset\\2015-12-29_190411_104.log.part08_sorted.csv\n",
      "loading file: F:\\SWaT Dataset\\2015-12-29_190411_104.log.part09_sorted.csv\n",
      "loading file: F:\\SWaT Dataset\\2015-12-29_190411_104.log.part10_sorted.csv\n"
     ]
    }
   ],
   "source": [
    "dataframes = []\n",
    "\n",
    "for filename in g[490:500]:\n",
    "    print(\"loading file: {}\".format(filename))\n",
    "    dataframes.append(pd.read_csv(filename,error_bad_lines = False, sep=\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>orig</th>\n",
       "      <th>type</th>\n",
       "      <th>i/f_name</th>\n",
       "      <th>i/f_dir</th>\n",
       "      <th>src</th>\n",
       "      <th>dst</th>\n",
       "      <th>proto</th>\n",
       "      <th>appi_name</th>\n",
       "      <th>proxy_src_ip</th>\n",
       "      <th>Modbus_Function_Code</th>\n",
       "      <th>Modbus_Function_Description</th>\n",
       "      <th>Modbus_Transaction_ID</th>\n",
       "      <th>SCADA_Tag</th>\n",
       "      <th>Modbus_Value</th>\n",
       "      <th>service</th>\n",
       "      <th>s_port</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>29Dec2015</td>\n",
       "      <td>13:39:41</td>\n",
       "      <td>192.168.1.48</td>\n",
       "      <td>log</td>\n",
       "      <td>eth1</td>\n",
       "      <td>outbound</td>\n",
       "      <td>192.168.1.10</td>\n",
       "      <td>192.168.1.20</td>\n",
       "      <td>tcp</td>\n",
       "      <td>CIP_read_tag_service</td>\n",
       "      <td>192.168.1.10</td>\n",
       "      <td>76.0</td>\n",
       "      <td>Read Tag Service</td>\n",
       "      <td>62639.0</td>\n",
       "      <td>HMI_FIT201</td>\n",
       "      <td>Number of Elements: 1</td>\n",
       "      <td>44818.0</td>\n",
       "      <td>54592.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>29Dec2015</td>\n",
       "      <td>13:39:41</td>\n",
       "      <td>192.168.1.48</td>\n",
       "      <td>log</td>\n",
       "      <td>eth1</td>\n",
       "      <td>outbound</td>\n",
       "      <td>192.168.1.30</td>\n",
       "      <td>192.168.1.40</td>\n",
       "      <td>tcp</td>\n",
       "      <td>CIP_read_tag_service</td>\n",
       "      <td>192.168.1.30</td>\n",
       "      <td>76.0</td>\n",
       "      <td>Read Tag Service - Response</td>\n",
       "      <td>7644.0</td>\n",
       "      <td>HMI_LIT401</td>\n",
       "      <td>0x03 0xa7 0x66 0x44; 0x00 0x00 0x00 0x00; 0x00...</td>\n",
       "      <td>44818.0</td>\n",
       "      <td>52544.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>29Dec2015</td>\n",
       "      <td>13:39:41</td>\n",
       "      <td>192.168.1.48</td>\n",
       "      <td>log</td>\n",
       "      <td>eth1</td>\n",
       "      <td>outbound</td>\n",
       "      <td>192.168.1.60</td>\n",
       "      <td>192.168.1.10</td>\n",
       "      <td>tcp</td>\n",
       "      <td>CIP_read_tag_service</td>\n",
       "      <td>192.168.1.60</td>\n",
       "      <td>76.0</td>\n",
       "      <td>Read Tag Service</td>\n",
       "      <td>13765.0</td>\n",
       "      <td>HMI_LIT101</td>\n",
       "      <td>Number of Elements: 1</td>\n",
       "      <td>44818.0</td>\n",
       "      <td>53260.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>29Dec2015</td>\n",
       "      <td>13:39:41</td>\n",
       "      <td>192.168.1.48</td>\n",
       "      <td>log</td>\n",
       "      <td>eth1</td>\n",
       "      <td>outbound</td>\n",
       "      <td>192.168.1.60</td>\n",
       "      <td>192.168.1.20</td>\n",
       "      <td>tcp</td>\n",
       "      <td>CIP_read_tag_service</td>\n",
       "      <td>192.168.1.60</td>\n",
       "      <td>76.0</td>\n",
       "      <td>Read Tag Service</td>\n",
       "      <td>57718.0</td>\n",
       "      <td>HMI_AIT202</td>\n",
       "      <td>Number of Elements: 1</td>\n",
       "      <td>44818.0</td>\n",
       "      <td>53250.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>29Dec2015</td>\n",
       "      <td>13:39:41</td>\n",
       "      <td>192.168.1.48</td>\n",
       "      <td>log</td>\n",
       "      <td>eth1</td>\n",
       "      <td>outbound</td>\n",
       "      <td>192.168.1.60</td>\n",
       "      <td>192.168.1.10</td>\n",
       "      <td>tcp</td>\n",
       "      <td>CIP_read_tag_service</td>\n",
       "      <td>192.168.1.60</td>\n",
       "      <td>76.0</td>\n",
       "      <td>Read Tag Service - Response</td>\n",
       "      <td>13765.0</td>\n",
       "      <td>HMI_LIT101</td>\n",
       "      <td>0x44 0x5e 0x02 0x44; 0x00 0x00 0x00 0x00; 0x00...</td>\n",
       "      <td>44818.0</td>\n",
       "      <td>53260.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num       date      time          orig type i/f_name   i/f_dir  \\\n",
       "0    1  29Dec2015  13:39:41  192.168.1.48  log     eth1  outbound   \n",
       "1    2  29Dec2015  13:39:41  192.168.1.48  log     eth1  outbound   \n",
       "2    3  29Dec2015  13:39:41  192.168.1.48  log     eth1  outbound   \n",
       "3    4  29Dec2015  13:39:41  192.168.1.48  log     eth1  outbound   \n",
       "4    5  29Dec2015  13:39:41  192.168.1.48  log     eth1  outbound   \n",
       "\n",
       "            src           dst proto             appi_name  proxy_src_ip  \\\n",
       "0  192.168.1.10  192.168.1.20   tcp  CIP_read_tag_service  192.168.1.10   \n",
       "1  192.168.1.30  192.168.1.40   tcp  CIP_read_tag_service  192.168.1.30   \n",
       "2  192.168.1.60  192.168.1.10   tcp  CIP_read_tag_service  192.168.1.60   \n",
       "3  192.168.1.60  192.168.1.20   tcp  CIP_read_tag_service  192.168.1.60   \n",
       "4  192.168.1.60  192.168.1.10   tcp  CIP_read_tag_service  192.168.1.60   \n",
       "\n",
       "   Modbus_Function_Code  Modbus_Function_Description  Modbus_Transaction_ID  \\\n",
       "0                  76.0             Read Tag Service                62639.0   \n",
       "1                  76.0  Read Tag Service - Response                 7644.0   \n",
       "2                  76.0             Read Tag Service                13765.0   \n",
       "3                  76.0             Read Tag Service                57718.0   \n",
       "4                  76.0  Read Tag Service - Response                13765.0   \n",
       "\n",
       "    SCADA_Tag                                       Modbus_Value  service  \\\n",
       "0  HMI_FIT201                              Number of Elements: 1  44818.0   \n",
       "1  HMI_LIT401  0x03 0xa7 0x66 0x44; 0x00 0x00 0x00 0x00; 0x00...  44818.0   \n",
       "2  HMI_LIT101                              Number of Elements: 1  44818.0   \n",
       "3  HMI_AIT202                              Number of Elements: 1  44818.0   \n",
       "4  HMI_LIT101  0x44 0x5e 0x02 0x44; 0x00 0x00 0x00 0x00; 0x00...  44818.0   \n",
       "\n",
       "    s_port  Tag  \n",
       "0  54592.0    0  \n",
       "1  52544.0    0  \n",
       "2  53260.0    0  \n",
       "3  53250.0    0  \n",
       "4  53260.0    0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat(dataframes,ignore_index=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping columns which are not useful for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([ \"date\", \"time\",'num'], axis=1)\n",
    "df = df[df['i/f_dir']=='outbound']\n",
    "df = df[df['src'].notna()]\n",
    "df = df[df['dst'].notna()]\n",
    "df = df[df['orig'].notna()]\n",
    "df = df[df['proxy_src_ip'].notna()]\n",
    "df = df[df['Modbus_Function_Code'].notna()]\n",
    "df = df[df['Modbus_Function_Description'].notna()]\n",
    "df = df[df['Modbus_Transaction_ID'].notna()]\n",
    "df = df[df['SCADA_Tag'].notna()]\n",
    "df = df[df['appi_name'].notna()]\n",
    "df = df[df['proto'].notna()]\n",
    "df = df[df['type'].notna()]\n",
    "df = df[df['Modbus_Value'].notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting hexadecimal to numeric using our function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import binascii, struct\n",
    "\n",
    "def modbus_conversion(value):\n",
    "    lst = []\n",
    "    for i in range(len(value.split(\";\"))):\n",
    "        x = value.split(\";\")[i]\n",
    "        if \" \" in x:\n",
    "            x = x.replace(\" \",\"\")\n",
    "        if '0x' in x:\n",
    "            x = x.replace(\"0x\",\"\")\n",
    "            x = struct.unpack('<f',binascii.unhexlify(x))[0]\n",
    "        lst.append(x)\n",
    "    return lst[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Modbus_Value'] != 'Number of Elements: 1']\n",
    "df['Modbus_Value'] = list(map(modbus_conversion,df['Modbus_Value']))\n",
    "df = df.drop(['i/f_dir','i/f_name'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting IP addresses to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KISHALAY\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:617: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\KISHALAY\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "import socket, struct\n",
    "\n",
    "def ip2long(ip):\n",
    "    \"\"\"\n",
    "    Convert an IP string to long\n",
    "    \"\"\"\n",
    "    packedIP = socket.inet_aton(ip)\n",
    "    return struct.unpack(\"!L\", packedIP)[0]\n",
    "\n",
    "\n",
    "df['src'] = list(map(ip2long,df['src']))\n",
    "df['dst'] = list(map(ip2long,df['dst']))\n",
    "df['orig'] = list(map(ip2long,df['orig']))\n",
    "df['proxy_src_ip'] = list(map(ip2long,df['proxy_src_ip']))\n",
    "\n",
    "df[['src','dst','orig','proxy_src_ip','Modbus_Value','Modbus_Function_Code','Modbus_Transaction_ID','s_port','service']] = StandardScaler().fit_transform(df[['src','dst','orig','proxy_src_ip','Modbus_Value','Modbus_Function_Code','Modbus_Transaction_ID','s_port','service']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Factorising certain columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SCADA_Tag'] = pd.factorize(df.SCADA_Tag)[0]\n",
    "df['Modbus_Function_Description'] = pd.factorize(df.Modbus_Function_Description)[0]\n",
    "df['appi_name'] = pd.factorize(df.appi_name)[0]\n",
    "df['proto'] = pd.factorize(df.proto)[0]\n",
    "df['type'] = pd.factorize(df.type)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Tag']\n",
    "df = df.drop('Tag',axis=1)\n",
    "x = df.values\n",
    "X_train, X_test, y_train, y_test =train_test_split(x,y, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy import stats\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1874874/1874874 [==============================] - 3s 2us/step - loss: 0.2372 - acc: 0.9443\n",
      "Epoch 2/10\n",
      "1874874/1874874 [==============================] - 2s 1us/step - loss: 0.2120 - acc: 0.9454\n",
      "Epoch 3/10\n",
      "1874874/1874874 [==============================] - 2s 1us/step - loss: 0.2119 - acc: 0.9454\n",
      "Epoch 4/10\n",
      "1874874/1874874 [==============================] - 2s 1us/step - loss: 0.2119 - acc: 0.9454\n",
      "Epoch 5/10\n",
      "1874874/1874874 [==============================] - 2s 1us/step - loss: 0.2119 - acc: 0.9454\n",
      "Epoch 6/10\n",
      "1874874/1874874 [==============================] - 2s 1us/step - loss: 0.2119 - acc: 0.9454\n",
      "Epoch 7/10\n",
      "1874874/1874874 [==============================] - 3s 1us/step - loss: 0.2119 - acc: 0.9454\n",
      "Epoch 8/10\n",
      "1874874/1874874 [==============================] - 3s 1us/step - loss: 0.2118 - acc: 0.9454\n",
      "Epoch 9/10\n",
      "1874874/1874874 [==============================] - 2s 1us/step - loss: 0.2118 - acc: 0.9454\n",
      "Epoch 10/10\n",
      "1874874/1874874 [==============================] - 2s 1us/step - loss: 0.2117 - acc: 0.9454\n",
      "1874874/1874874 [==============================] - 19s 10us/step\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(56, input_dim=14, activation='sigmoid'))\n",
    "model.add(Dense(56, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=10000)\n",
    "scaledtorscores = model.evaluate(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating predictions and calculating confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[590688,      0],\n",
       "       [ 34271,      0]], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "\n",
    "lt = [1]*len(y_test)\n",
    "\n",
    "for i in range(len(predictions)):\n",
    "    if predictions[i] >= 0.5:\n",
    "        lt[i] = 1\n",
    "    else:\n",
    "        lt[i] = 0\n",
    "        \n",
    "\n",
    "matrix = confusion_matrix(y_test,lt)\n",
    "matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Requirements (ALWAYS RUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prelim - Import Packages\n",
    "import csv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn import tree\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "import pickle\n",
    "pickleFolder=os.getcwd()+\"/Pickles/SuperPickles\"\n",
    "\n",
    "IncludeConst=False\n",
    "\n",
    "def loadLists():\n",
    "    with open(pickleFolder+\"/actuatorList.csv\", \"r\") as outfile:\n",
    "        readfile=csv.reader(outfile)\n",
    "        actuator_list=[x for x in readfile][0]\n",
    "    with open(pickleFolder+\"/sensorList.csv\", \"r\") as outfile:\n",
    "        readfile=csv.reader(outfile)\n",
    "        sensor_list=[x for x in readfile][0]\n",
    "    return(actuator_list,sensor_list)\n",
    "\n",
    "def percentageBar(current, limit, length=50):\n",
    "    clear_output(wait=True)\n",
    "    a=\"\"\n",
    "    b=\"\"\n",
    "    for k in range(0,math.floor(current*length/limit)):\n",
    "        a=a+\"*\"\n",
    "    for l in range(math.floor(current*length/limit),length):\n",
    "        b=b+\"-\"\n",
    "    print(\"%i %%\" % (100*current/limit))\n",
    "    print(\"[\"+a+b+\"]\")\n",
    "    \n",
    "h=open(\"/home/sharding/Documents/SummerProject/Data/AttackList_Indexed.csv\",\"r+\")\n",
    "file_atcklist=csv.reader(h)\n",
    "top=next(file_atcklist)\n",
    "attack_list=pd.DataFrame(file_atcklist)\n",
    "base=time.strptime('12/28/2015 10:00:00', '%m/%d/%Y %H:%M:%S')\n",
    "tail=120\n",
    "attack_start_times=[]\n",
    "for t in range(0,len(attack_list)):\n",
    "    attack_start_times.append(int(time.mktime(time.strptime(attack_list.iloc[t][1], '%m/%d/%Y %H:%M:%S'))-time.mktime(base)))\n",
    "attack_start_times=np.array(attack_start_times)\n",
    "attack_end_times=[]\n",
    "for t in range(0,len(attack_list)):\n",
    "    attack_end_times.append(int(time.mktime(time.strptime(attack_list.iloc[t][2], '%m/%d/%Y %H:%M:%S'))-time.mktime(base)+tail))\n",
    "attack_end_times=np.array(attack_end_times)\n",
    "attack_bins=np.transpose(np.vstack((attack_start_times,attack_end_times)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prelim - Load Data\n",
    "\n",
    "f=open(\"/home/sharding/Documents/SummerProject/Data/SWaT_Dataset_Normal_v1.csv\",\"r+\")\n",
    "g=open(\"/home/sharding/Documents/SummerProject/Data/SWaT_Attack.csv\",\"r+\")\n",
    "file=csv.reader(f)\n",
    "top=next(file)\n",
    "file_atck=csv.reader(g)\n",
    "col_names=[x.strip() for x in next(file)]\n",
    "col_names_atck=[x.strip() for x in next(file_atck)]\n",
    "dataNorm=pd.DataFrame(file)\n",
    "dataNorm.columns=col_names\n",
    "dataAtck=pd.DataFrame(file_atck)\n",
    "dataAtck.columns=col_names_atck\n",
    "\n",
    "\n",
    "#Prelim - Pickles\n",
    "\n",
    "dataNorm.to_pickle(pickleFolder+\"/ChocolateRiver_Normal.pkl\")\n",
    "dataAtck.to_pickle(pickleFolder+\"/ChocolateRiver_Attack.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Set Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gather Pickles\n",
    "dataNorm=pd.read_pickle(pickleFolder+\"/ChocolateRiver_Normal.pkl\")\n",
    "dataAtck=pd.read_pickle(pickleFolder+\"/ChocolateRiver_Attack.pkl\")\n",
    "\n",
    "\n",
    "#Transformation (GENERAL) - Set Lists\n",
    "\n",
    "actuator_list=[\"MV101\",\"P101\",\"P102\",\"MV201\",\"P201\",\"P202\",\"P203\",\"P204\",\"P205\",\"P206\",\"MV301\",\"MV302\",\"MV303\",\"MV304\",\"P301\",\"P302\",\"P401\",\"P402\",\"P403\",\"P404\",\"P501\",\"P502\",\"P601\",\"P602\",\"P603\"]\n",
    "actuator_set=set(actuator_list)\n",
    "sensor_list=[item for item in dataNorm.columns if item not in actuator_set and item not in [\"Timestamp\",\"Normal/Attack\"]]\n",
    "generalRegression_normal=dataNorm.drop([\"Timestamp\",\"Normal/Attack\"], axis=1).copy()\n",
    "generalRegression_attack=dataAtck.drop([\"Normal/Attack\"], axis=1).copy()\n",
    "\n",
    "\n",
    "#Transformation (GENERAL) - Numerise Columns\n",
    "\n",
    "for x in generalRegression_normal.columns:\n",
    "    generalRegression_normal[x]=pd.to_numeric(generalRegression_normal[x])\n",
    "for x in generalRegression_attack.columns:\n",
    "    if x != \"Timestamp\":\n",
    "        generalRegression_attack[x]=pd.to_numeric(generalRegression_attack[x])\n",
    "\n",
    "    \n",
    "#Transformation (GENERAL) - Adjust Pump Settings\n",
    "\n",
    "for x in actuator_list:\n",
    "    if \"P\" in x:\n",
    "        generalRegression_normal[x]=generalRegression_normal[x]-1\n",
    "        generalRegression_attack[x]=generalRegression_attack[x]-1\n",
    "\n",
    "\n",
    "#Transformation (GENERAL) - Pickles\n",
    "generalRegression_normal.to_pickle(pickleFolder+\"/GeneralKenobi_Normal.pkl\")\n",
    "generalRegression_attack.to_pickle(pickleFolder+\"/GeneralKenobi_Attack.pkl\")\n",
    "with open(pickleFolder+\"/actuatorList.csv\", \"w\") as outfile:\n",
    "    writer=csv.writer(outfile)\n",
    "    writer.writerow(actuator_list)\n",
    "with open(pickleFolder+\"/sensorList.csv\", \"w\") as outfile:\n",
    "    writer=csv.writer(outfile)\n",
    "    writer.writerow(sensor_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actuator Set Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gather Pickles\n",
    "\n",
    "generalRegression_normal=pd.read_pickle(pickleFolder+\"/GeneralKenobi_Normal.pkl\")\n",
    "generalRegression_attack=pd.read_pickle(pickleFolder+\"/GeneralKenobi_Attack.pkl\")\n",
    "(actuator_list,sensor_list)=loadLists()\n",
    "\n",
    "\n",
    "#Transformation (ACTUATOR) - Change over Second (Sensors)\n",
    "\n",
    "actuatorSet_normal=generalRegression_normal.copy()\n",
    "actuatorSet_attack=generalRegression_attack.copy()\n",
    "for sen in sensor_list:\n",
    "    actuatorSet_normal[sen+\"_Sec_Diff\"]=np.hstack((0,(np.array(actuatorSet_normal[sen][1:])-np.array(actuatorSet_normal[sen][:-1]))))\n",
    "    actuatorSet_attack[sen+\"_Sec_Diff\"]=np.hstack((0,(np.array(actuatorSet_attack[sen][1:])-np.array(actuatorSet_attack[sen][:-1]))))\n",
    "\n",
    "    \n",
    "#Transformation (ACTUATOR) - Change over Last 10 Min (Sensors)\n",
    "\n",
    "secHistory=600\n",
    "for sen in sensor_list:\n",
    "    actuatorSet_normal[sen+\"_10min_Diff\"]=np.hstack((np.repeat(0,secHistory),(np.array(actuatorSet_normal[sen][secHistory:])-np.array(actuatorSet_normal[sen][:-secHistory]))))\n",
    "    actuatorSet_attack[sen+\"_10min_Diff\"]=np.hstack((np.repeat(0,secHistory),(np.array(actuatorSet_attack[sen][secHistory:])-np.array(actuatorSet_attack[sen][:-secHistory]))))\n",
    "\n",
    "    \n",
    "#Transformation (ACTUATOR) - Pickles\n",
    "\n",
    "actuatorSet_normal.to_pickle(pickleFolder+\"/Actu8rBoi_Normal.pkl\")\n",
    "actuatorSet_attack.to_pickle(pickleFolder+\"/Actu8rBoi_Attack.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sensor Set Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gather Pickles\n",
    "\n",
    "generalRegression_normal=pd.read_pickle(pickleFolder+\"/GeneralKenobi_Normal.pkl\")\n",
    "generalRegression_attack=pd.read_pickle(pickleFolder+\"/GeneralKenobi_Attack.pkl\")\n",
    "(actuator_list,sensor_list)=loadLists()\n",
    "\n",
    "\n",
    "#Transformation (SENSOR) - Split MV Columns\n",
    "\n",
    "sensorSet_normal=generalRegression_normal.copy()\n",
    "sensorSet_attack=generalRegression_attack.copy()\n",
    "for act in [x for x in actuator_list if \"MV\" in x]:\n",
    "    sensorSet_normal[act+\"_1\"]=np.array([int(x) for x in list(sensorSet_normal[act]==1)])\n",
    "    sensorSet_normal[act+\"_2\"]=np.array([int(x) for x in list(sensorSet_normal[act]==2)])\n",
    "    sensorSet_attack[act+\"_1\"]=np.array([int(x) for x in list(sensorSet_attack[act]==1)])\n",
    "    sensorSet_attack[act+\"_2\"]=np.array([int(x) for x in list(sensorSet_attack[act]==2)])\n",
    "    sensorSet_normal=sensorSet_normal.drop([act],axis=1)\n",
    "    sensorSet_attack=sensorSet_attack.drop([act],axis=1)\n",
    "\n",
    "\n",
    "#Transformation (SENSOR) - Constant Column\n",
    "\n",
    "sensorSet_attack[\"Const\"]=np.repeat(1,len(sensorSet_attack))\n",
    "sensorSet_normal[\"Const\"]=np.repeat(1,len(sensorSet_normal))\n",
    "\n",
    "\n",
    "#Transformation (SENSOR) - Previous Value Columns\n",
    "\n",
    "sensorSet_prev_val_norm={}\n",
    "sensorSet_prev_val_atck={}\n",
    "for col in sensor_list:\n",
    "    sensorSet_prev_val_atck[\"{0}_Prev\".format(col)]=np.hstack((sensorSet_attack[col][0],np.array(sensorSet_attack[col][:-1])))\n",
    "    sensorSet_prev_val_norm[\"{0}_Prev\".format(col)]=np.hstack((sensorSet_normal[col][0],np.array(sensorSet_normal[col][:-1])))\n",
    "    \n",
    "\n",
    "#Transformation (SENSOR) - Pickles\n",
    "sensorSet_attack.to_pickle(pickleFolder+\"/SpideySense_Attack.pkl\")\n",
    "sensorSet_normal.to_pickle(pickleFolder+\"/SpideySense_Normal.pkl\")\n",
    "with open(pickleFolder+\"/SensorSetPrevValNorm.pkl\",\"wb\") as outfile:\n",
    "    pickle.dump(sensorSet_prev_val_norm,outfile)\n",
    "with open(pickleFolder+\"/SensorSetPrevValAtck.pkl\",\"wb\") as outfile:\n",
    "    pickle.dump(sensorSet_prev_val_atck,outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Model - Actuators (Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gather Pickles\n",
    "\n",
    "actuatorSet_normal=pd.read_pickle(pickleFolder+\"/Actu8rBoi_Normal.pkl\")\n",
    "actuatorSet_attack=pd.read_pickle(pickleFolder+\"/Actu8rBoi_Attack.pkl\")\n",
    "(actuator_list,sensor_list)=loadLists()\n",
    "\n",
    "\n",
    "#Logistic Regression Model - Training Regressors\n",
    "\n",
    "logisticRegressorActuatorDict={}\n",
    "count=0\n",
    "for act in actuator_list:\n",
    "    targetVector=np.array(actuatorSet_normal[act])\n",
    "    trainingData=actuatorSet_normal.drop(act, axis=1).values\n",
    "    logisticRegressorActuatorDict[\"{0}_Regressor\".format(act)]=linear_model.LogisticRegression()\n",
    "    try:\n",
    "        logisticRegressorActuatorDict[\"{0}_Regressor\".format(act)].fit(trainingData,targetVector)\n",
    "    except:\n",
    "        trainingData[0]=1-trainingData[0]\n",
    "        logisticRegressorActuatorDict[\"{0}_Regressor\".format(act)].fit(trainingData,targetVector)\n",
    "    count+=1\n",
    "    percentageBar(count,len(actuator_list))\n",
    "\n",
    "\n",
    "#Logistic Regression Model - Pickles\n",
    "\n",
    "outfile=open(pickleFolder+\"/LogisticClassifiers.pkl\",\"wb\")\n",
    "pickle.dump(logisticRegressorActuatorDict,outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetVector[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Model - Actuators (Predicting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gather Pickles\n",
    "\n",
    "actuatorSet_normal=pd.read_pickle(pickleFolder+\"/Actu8rBoi_Normal.pkl\")\n",
    "actuatorSet_attack=pd.read_pickle(pickleFolder+\"/Actu8rBoi_Attack.pkl\")\n",
    "(actuator_list,sensor_list)=loadLists()\n",
    "infile=open(pickleFolder+\"/LogisticClassifiers.pkl\",\"rb\")\n",
    "logisticRegressorActuatorDict=pickle.load(infile)\n",
    "\n",
    "\n",
    "#Logistic Regression Model - Predict Attack Data\n",
    "\n",
    "probData_actuator_logistic=pd.DataFrame([], columns=actuator_list)\n",
    "count=0\n",
    "for act in actuator_list:\n",
    "    prob_vec=[]\n",
    "    classifier=logisticRegressorActuatorDict[\"{0}_Regressor\".format(act)]\n",
    "    testData=actuatorSet_attack.drop([act,\"Timestamp\"], axis=1).values\n",
    "    obsvData=np.array(actuatorSet_attack[act])\n",
    "    for t in range(0,len(testData)):\n",
    "        x=testData[t]\n",
    "        try:\n",
    "            u=classifier.predict_proba(x.reshape(1,-1))[0][obsvData[t]]\n",
    "            if u == 0:\n",
    "                u=0.0000001\n",
    "        except:\n",
    "            u=0.0000001\n",
    "        prob_vec.append(u)\n",
    "    probData_actuator_logistic[act]=np.array(prob_vec)\n",
    "    count+=1\n",
    "    percentageBar(count,len(actuator_list))\n",
    "    \n",
    "    \n",
    "#Logistic Regression Model - Pickles\n",
    "\n",
    "probData_actuator_logistic.to_pickle(pickleFolder+\"/ActuatorProbMatrixLogistic.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF Model - Actuators (Traning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gather Pickles\n",
    "\n",
    "actuatorSet_normal=pd.read_pickle(pickleFolder+\"/Actu8rBoi_Normal.pkl\")\n",
    "actuatorSet_attack=pd.read_pickle(pickleFolder+\"/Actu8rBoi_Attack.pkl\")\n",
    "(actuator_list,sensor_list)=loadLists()\n",
    "\n",
    "\n",
    "#RF Model - Traning Forests\n",
    "\n",
    "forestClassifierActuatorDict={}\n",
    "count=0\n",
    "for act in actuator_list:\n",
    "    targetVector=np.array(actuatorSet_normal[act])\n",
    "    trainingData=actuatorSet_normal.drop(act, axis=1).values\n",
    "    forestClassifierActuatorDict[\"{0}_Classifier\".format(act)]=tree.DecisionTreeClassifier()\n",
    "    forestClassifierActuatorDict[\"{0}_Classifier\".format(act)].fit(trainingData,targetVector)\n",
    "    count+=1\n",
    "    percentageBar(count,len(actuator_list))\n",
    "\n",
    "\n",
    "#RF Model - Pickles\n",
    "\n",
    "outfile=open(pickleFolder+\"/ForestClassifiers.pkl\",\"wb\")\n",
    "pickle.dump(forestClassifierActuatorDict, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF Model - Actuators (Predicting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gather Pickles\n",
    "\n",
    "actuatorSet_normal=pd.read_pickle(pickleFolder+\"/Actu8rBoi_Normal.pkl\")\n",
    "actuatorSet_attack=pd.read_pickle(pickleFolder+\"/Actu8rBoi_Attack.pkl\")\n",
    "(actuator_list,sensor_list)=loadLists()\n",
    "with open(pickleFolder+\"/ForestClassifiers.pkl\",\"rb\") as infile:\n",
    "    forestClassifierActuatorDict=pickle.load(infile)\n",
    "\n",
    "\n",
    "#RF Model - Predict Attack Data\n",
    "\n",
    "probData_actuator_RF=pd.DataFrame([], columns=actuator_list)\n",
    "count=0\n",
    "for act in actuator_list:\n",
    "    prob_vec=[]\n",
    "    classifier=forestClassifierActuatorDict[\"{0}_Classifier\".format(act)]\n",
    "    testData=actuatorSet_attack.drop([act,\"Timestamp\"], axis=1).values\n",
    "    obsvData=np.array(actuatorSet_attack[act])\n",
    "    for t in range(0,len(testData)):\n",
    "        x=testData[t]\n",
    "        try:\n",
    "            u=classifier.predict_proba(x.reshape(1,-1))[0][obsvData[t]]\n",
    "            if u == 0:\n",
    "                u=0.0000001\n",
    "        except:\n",
    "            u=0.0000001\n",
    "        prob_vec.append(u)\n",
    "    probData_actuator_RF[act]=np.array(prob_vec)\n",
    "    count+=1\n",
    "    percentageBar(count,len(actuator_list))\n",
    "\n",
    "\n",
    "#RF Model - Combined Values\n",
    "\n",
    "combinedValue=[]\n",
    "for x in probData_actuator_RF.values:\n",
    "    combinedValue.append(sum(np.log(x)))\n",
    "probData_actuator_RF[\"Combined\"]=-2*np.array(combinedValue)\n",
    "probData_actuator_RF[\"Time\"]=np.array([int(time.mktime(time.strptime(t, \" %d/%m/%Y %I:%M:%S %p\"))-time.mktime(base)) for t in np.array(actuatorSet_attack[\"Timestamp\"])]) \n",
    "\n",
    "\n",
    "#RF Model - Pickles\n",
    "\n",
    "probData_actuator_RF.to_pickle(pickleFolder+\"/ActuatorProbMatrixRF.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Model - Sensors (Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gather Pickles\n",
    "\n",
    "sensorSet_attack=pd.read_pickle(pickleFolder+\"/SpideySense_Attack.pkl\")\n",
    "sensorSet_normal=pd.read_pickle(pickleFolder+\"/SpideySense_Normal.pkl\")\n",
    "(actuator_list,sensor_list)=loadLists()\n",
    "with open(pickleFolder + \"/SensorSetPrevValNorm.pkl\",\"rb\") as infile:\n",
    "    sensorSet_prev_val_norm=pickle.load(infile)\n",
    "with open(pickleFolder + \"/SensorSetPrevValAtck.pkl\",\"rb\") as infile:\n",
    "    sensorSet_prev_val_atck=pickle.load(infile)\n",
    "    \n",
    "\n",
    "#Linear Model - Include Constant Column\n",
    "\n",
    "if IncludeConst==False:\n",
    "    sensorSet_attack=sensorSet_attack.drop([\"Const\"],axis=1)\n",
    "    sensorSet_normal=sensorSet_normal.drop([\"Const\"],axis=1)\n",
    "    \n",
    "\n",
    "#Linear Model - Train Linear Regressor\n",
    "\n",
    "linearRegressorSensorDict={}\n",
    "linearRegressorPredList={}\n",
    "linearRegressorDiffList={}\n",
    "count=0\n",
    "for sen in sensor_list:\n",
    "    dataFramez=sensorSet_normal.copy()\n",
    "    dataFramez[\"{0}_Prev\".format(sen)]=sensorSet_prev_val_norm[\"{0}_Prev\".format(sen)]\n",
    "    targetVector=np.array(dataFramez[sen])\n",
    "    trainingData=dataFramez.drop([sen], axis=1).values\n",
    "    linearRegressorSensorDict[\"{0}_Regressor\".format(sen)]=linear_model.LinearRegression()\n",
    "    linearRegressorSensorDict[\"{0}_Regressor\".format(sen)].fit(trainingData,targetVector)\n",
    "    pred=[]\n",
    "    for X in trainingData:\n",
    "        m=linearRegressorSensorDict[\"{0}_Regressor\".format(sen)].predict(np.array(X).reshape(1,-1))\n",
    "        pred.append(m)\n",
    "    pred=np.array([float(x) for x in pred])\n",
    "    linearRegressorPredList[\"{0}_Pred\".format(sen)]=pred\n",
    "    linearRegressorDiffList[\"{0}_Diff\".format(sen)]=pred-np.array(targetVector)\n",
    "    count+=1\n",
    "    percentageBar(count,len(sensor_list))\n",
    "\n",
    "\n",
    "#Linear Model - Pickles\n",
    "\n",
    "outfile=open(pickleFolder+\"/LinearRegressors.pkl\",\"wb\")\n",
    "pickle.dump(linearRegressorSensorDict, outfile)\n",
    "outfile=open(pickleFolder+\"/LinearRegressorDiffList.pkl\",\"wb\")\n",
    "pickle.dump(linearRegressorDiffList, outfile)\n",
    "outfile=open(pickleFolder+\"/LinearRegressorPredList.pkl\",\"wb\")\n",
    "pickle.dump(linearRegressorPredList, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram Method - Sensors (P-Value Dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Gather Pickles\n",
    "\n",
    "sensorSet_attack=pd.read_pickle(pickleFolder+\"/SpideySense_Attack.pkl\")\n",
    "sensorSet_normal=pd.read_pickle(pickleFolder+\"/SpideySense_Normal.pkl\")\n",
    "(actuator_list,sensor_list)=loadLists()\n",
    "#infile=open(pickleFolder+\"/LinearRegressorPredList.pkl\",\"rb\")\n",
    "#linearRegressorPredList=pickle.load(infile)\n",
    "infile=open(pickleFolder+\"/LinearRegressorDiffList.pkl\",\"rb\")\n",
    "linearRegressorDiffList=pickle.load(infile)\n",
    "infile=open(pickleFolder+\"/LinearRegressors.pkl\",\"rb\")\n",
    "linearRegressorSensorDict=pickle.load(infile)\n",
    "\n",
    "\n",
    "#Histogram Method - Histogram Generation\n",
    "\n",
    "histogram_dict={}\n",
    "for sen in sensor_list:\n",
    "    plt.figure(figsize=(20,10))\n",
    "    num_bins=100\n",
    "    n, bins, patches = plt.hist(linearRegressorDiffList[\"{0}_Diff\".format(sen)], bins=np.arange(-5,5,0.05))\n",
    "    plt.title(\"Normal Histogram %s\" % sen)\n",
    "    histogram_dict[\"{0}_norm_hist\".format(sen)]=n\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "#Histogram Method - Histogram to P-value\n",
    "\n",
    "hist_data=pd.DataFrame([],columns=sensor_list)\n",
    "count=0\n",
    "for sen in sensor_list:\n",
    "    normalisedHist=histogram_dict[\"{0}_norm_hist\".format(sen)]/sum(histogram_dict[\"{0}_norm_hist\".format(sen)])\n",
    "    hist_data[sen]=normalisedHist\n",
    "    count+=1\n",
    "    percentageBar(count,2*len(sensor_list))\n",
    "p_val_hist=hist_data.copy()\n",
    "for sen in sensor_list:\n",
    "    for i in range(0,len(hist_data)):\n",
    "        a=hist_data[sen][i]\n",
    "        truthVec=(hist_data[sen]<=a)\n",
    "        p_val_hist[sen][i]=sum(np.multiply(hist_data[sen],truthVec))\n",
    "    count+=1\n",
    "    percentageBar(count,2*len(sensor_list))\n",
    "    \n",
    "\n",
    "#Histogram Method - Pickles\n",
    "\n",
    "p_val_hist.to_pickle(pickleFolder+\"/PValue_Histogram.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram Method - Sensors (Attack Prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gather Pickles\n",
    "\n",
    "sensorSet_attack=pd.read_pickle(pickleFolder+\"/SpideySense_Attack.pkl\")\n",
    "sensorSet_normal=pd.read_pickle(pickleFolder+\"/SpideySense_Normal.pkl\")\n",
    "(actuator_list,sensor_list)=loadLists()\n",
    "with open(pickleFolder + \"/SensorSetPrevValNorm.pkl\",\"rb\") as infile:\n",
    "    sensorSet_prev_val_norm=pickle.load(infile)\n",
    "with open(pickleFolder + \"/SensorSetPrevValAtck.pkl\",\"rb\") as infile:\n",
    "    sensorSet_prev_val_atck=pickle.load(infile)\n",
    "infile=open(pickleFolder+\"/LinearRegressors.pkl\",\"rb\")\n",
    "linearRegressorSensorDict=pickle.load(infile)\n",
    "p_val_hist=pd.read_pickle(pickleFolder+\"/PValue_Histogram.pkl\")\n",
    "\n",
    "\n",
    "#Linear Model - Include Constant Column\n",
    "\n",
    "IncludeConst=True\n",
    "if IncludeConst==False:\n",
    "    sensorSet_attack=sensorSet_attack.drop([\"Const\"],axis=1)\n",
    "    sensorSet_normal=sensorSet_normal.drop([\"Const\"],axis=1)\n",
    "\n",
    "    \n",
    "#Histogram Method - Attack Predictions\n",
    "\n",
    "attack_predict_list_linreg={}\n",
    "count=0\n",
    "timeSteps=sensorSet_attack[\"Timestamp\"]\n",
    "sensorSet_attack=sensorSet_attack.drop([\"Timestamp\"],axis=1)\n",
    "for sen in sensor_list:\n",
    "    dataFramez=sensorSet_attack.copy()\n",
    "    dataFramez[\"{0}_Prev\".format(sen)]=sensorSet_prev_val_atck[\"{0}_Prev\".format(sen)]\n",
    "    obsvData=dataFramez[sen]\n",
    "    testData=dataFramez.drop([sen], axis=1).values\n",
    "    predList=[]\n",
    "    for x in testData:\n",
    "        u=linearRegressorSensorDict[\"{0}_Regressor\".format(sen)].predict(np.array(x).reshape(1,-1))\n",
    "        predList.append(u)\n",
    "    difflist=np.array([float(u) for u in predList])-np.array(obsvData)\n",
    "    attack_predict_list_linreg[\"{0}_Attack_Prediction\".format(sen)]=difflist\n",
    "    count+=1\n",
    "    percentageBar(count,len(sensor_list))\n",
    "\n",
    "\n",
    "#Histogram Method - Attack Bin Ref\n",
    "\n",
    "attack_diff_frame=pd.DataFrame([],columns=sensor_list)\n",
    "for sen in sensor_list:\n",
    "    attack_diff_frame[sen]=attack_predict_list_linreg[\"{0}_Attack_Prediction\".format(sen)]\n",
    "attack_pval_frame=((attack_diff_frame+5)/0.05).copy()\n",
    "count=0\n",
    "for col in attack_pval_frame:\n",
    "    L=np.array([math.floor(x) for x in attack_pval_frame[col]])\n",
    "    for i in range(0,len(attack_pval_frame)):\n",
    "        try:\n",
    "            if p_val_hist[col][L[i]]!=0:\n",
    "                attack_pval_frame[col][i]=p_val_hist[col][L[i]]\n",
    "            else:\n",
    "                attack_pval_frame[col][i]=0.0000001\n",
    "        except:\n",
    "            attack_pval_frame[col][i]=0.0000001\n",
    "    count+=1\n",
    "    percentageBar(count,len(sensor_list))\n",
    "\n",
    "\n",
    "#Histogram Method - Pickles\n",
    "\n",
    "attack_pval_frame.to_pickle(pickleFolder+\"/AttackRegressionPValues.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram Method - Combining P-Values (Only Sensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Gather Pickles\n",
    "\n",
    "attack_pval_frame=pd.read_pickle(pickleFolder+\"/AttackRegressionPValues.pkl\")\n",
    "sensorSet_attack=pd.read_pickle(pickleFolder+\"/SpideySense_Attack.pkl\")\n",
    "\n",
    "\n",
    "#Combining P-Values - Method Choice (Fisher's or Simes')\n",
    "\n",
    "Fishers=True\n",
    "\n",
    "\n",
    "#Combining P-Values - Genereating \n",
    "    \n",
    "combined=[]\n",
    "if Fishers==True:\n",
    "    for X in attack_pval_frame.values:\n",
    "        combined.append(-2*sum(np.log(X)))\n",
    "#ELSE!!!\n",
    "attack_pval_frame[\"Combined\"]=np.array(combined)\n",
    "\n",
    "\n",
    "#Timestamp\n",
    "\n",
    "timeSteps=sensorSet_attack[\"Timestamp\"]\n",
    "attack_pval_frame[\"Time\"]=np.array([int(time.mktime(time.strptime(t, \" %d/%m/%Y %I:%M:%S %p\"))-time.mktime(base)) for t in np.array(timeSteps)])\n",
    "\n",
    "\n",
    "#Combining P-Values - Pickles\n",
    "\n",
    "attack_pval_frame.to_pickle(pickleFolder+\"/LinearCombinedPValues.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "attack_pval_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataAtck=pd.read_pickle(pickleFolder+\"/ChocolateRiver_Attack.pkl\")\n",
    "\n",
    "\n",
    "#Histogram Method - Normal and Attack Times\n",
    "\n",
    "normalIndex=list(dataAtck.iloc[list(dataAtck[\"Normal/Attack\"]==\"Normal\")].index)\n",
    "attackIndex=list(dataAtck.iloc[list(dataAtck[\"Normal/Attack\"]!=\"Normal\")].index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gather Pickles\n",
    "\n",
    "probData_actuator_RF=pd.read_pickle(pickleFolder+\"/ActuatorProbMatrixRF.pkl\")\n",
    "\n",
    "\n",
    "\n",
    "#Plots - Plot\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "for m in attack_start_times:\n",
    "    plt.axvline(x=m,color=\"r\",linestyle=\"-\")\n",
    "for n in attack_end_times:\n",
    "    plt.axvline(x=n,color=\"g\",linestyle=\"-\")\n",
    "plt.plot(attack_pval_frame[\"Time\"],attack_pval_frame[\"Combined\"],\".b\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
